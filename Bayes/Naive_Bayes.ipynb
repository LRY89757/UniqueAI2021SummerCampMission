{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1]\n",
      "-0.6931471805599453\n",
      "[0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-6e0a8bb5c331>:46: RuntimeWarning: divide by zero encountered in log\n",
      "  self.p_c_1 = np.log(np.concatenate((p_c_1.reshape(1, -1), self.p_c_1.reshape(1, -1)), axis=0))\n",
      "<ipython-input-37-6e0a8bb5c331>:51: RuntimeWarning: divide by zero encountered in log\n",
      "  self.p_c_0 = np.log(np.concatenate((p_c_0.reshape(1, -1), self.p_c_0.reshape(1, -1)), axis=0))\n"
     ]
    }
   ],
   "source": [
    "# -*- coding=utf-8 -*-\n",
    "# @Time :2021/7/17 20:33\n",
    "# @Author :Lu runyu\n",
    "# @File : Naive_Bayes.ipynb\n",
    "# @Software : Jupyter Notebook\n",
    "\n",
    "\"\"\"\n",
    "    python3实现朴素贝叶斯分类器\n",
    "    以过滤spam为例, 实现二分类器\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveBayes:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.likelihood_1 = None\n",
    "        self.likelihood_0 = None\n",
    "        self.p_c_0 = None\n",
    "        self.p_c_1 = None\n",
    "        self.tag_num = None\n",
    "\n",
    "    def fit(self, dataset, labels):\n",
    "        \"\"\"\n",
    "        :param dataset: dataset is an one-hot-encoding numpy array\n",
    "        :param labels: corresponding tags\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        由于这里面的要计算的条件概率和先验概率实在是很少，我们就不打算引入字典类型，我们直接每一类都用列表描述就行了。\n",
    "        这里相当于：label:[y1, y2, y3, ……, yn](实际上只有0，1)\n",
    "        而我们的dataset中的每一条也即：Xi:[0, 1, 0, 1, 1, ……, 1, 0], 其类别为yi\\\n",
    "        我们要算出P(xi|yk),也要算出条件概率P(yk)\n",
    "        \"\"\"\n",
    "\n",
    "        # 首先是先验概率：\n",
    "        self.likelihood_0 = np.log(labels.tolist().count(0) / len(labels))\n",
    "        self.likelihood_1 = 0 - self.likelihood_0\n",
    "        \n",
    "        # 接下来是我们的条件概率：\n",
    "        index_1 = np.where(labels==1)  # 得到labels=1的索引\n",
    "        self.p_c_1 = np.sum(dataset[index_1], axis=0) / dataset[index_1].shape[0]   # 得到P(xi=1|yk=1)概率的矩阵\n",
    "        p_c_1 = (np.zeros(dataset.shape[1]) + 1) - self.p_c_1     # 得到P(xi=0|yk=1)概率的矩阵\n",
    "        self.p_c_1 = np.log(np.concatenate((p_c_1.reshape(1, -1), self.p_c_1.reshape(1, -1)), axis=0))\n",
    "        index_0 = np.where(labels==0) # 得到labels=0的索引\n",
    "        self.p_c_0 = np.sum(dataset[index_0], axis=0) / dataset[index_0].shape[0]   # 得到P(xi=1|yk=0)概率的矩阵\n",
    "        p_c_0 = (np.zeros(dataset.shape[1]) + 1) - self.p_c_0     # 得到P(xi=0|yk=0)概率的矩阵\n",
    "#         self.p_c_0 = np.log(np.array([].append(p_c_0).append(self.p_c_0)))\n",
    "        self.p_c_0 = np.log(np.concatenate((p_c_0.reshape(1, -1), self.p_c_0.reshape(1, -1)), axis=0))\n",
    "        \n",
    "\n",
    "    def predict(self, testset):\n",
    "        \"\"\"\n",
    "\n",
    "        :param testset: the dataset to be predicted(still one-hot-encoding)\n",
    "        :return: an array of labels\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        预测相对而言就比较简单了\n",
    "        \"\"\"\n",
    "        return np.array([np.argmax(np.array([self.likelihood_0 + sum([self.p_c_0[document[i]][i] for i in range(self.p_c_0.shape[1])]), self.likelihood_1 + sum([self.p_c_1[document[i]][i] for i in range(self.p_c_1.shape[1])])])) for document in testset])\n",
    "        \n",
    "        \n",
    "def loadDataSet():\n",
    "    postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "                   ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "                   ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "                   ['stop', 'posting', 'stupid', 'worthless', 'garbage'],\n",
    "                   ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "                   ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    classVec = [0, 1, 0, 1, 0, 1]  # 1 is abusive, 0 not\n",
    "    return postingList, classVec\n",
    "\n",
    "\n",
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])  # create empty set\n",
    "    for document in dataSet:\n",
    "        vocabSet = vocabSet | set(document)  # union of the two sets取并集\n",
    "    return list(vocabSet)   # 返回的是一个一维的，不含重复单词的列表，列表中包含所有dataSet中含有的单词。相当于一个字典（不是python里的那种字典）。\n",
    "\n",
    "\n",
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    returnVec = [0] * len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "\n",
    "    return returnVec    # 相当于一个one-hot编码\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    listOPosts, listClasses = loadDataSet()\n",
    "    VocabList = createVocabList(listOPosts)\n",
    "    train_dataset = []\n",
    "    for sentence in listOPosts:\n",
    "        train_dataset.append(setOfWords2Vec(VocabList, sentence))\n",
    "    train_dataset = np.array(train_dataset)\n",
    "    labelset = np.array(listClasses)\n",
    "    print(labelset)\n",
    "    nb_clf = NaiveBayes()\n",
    "    nb_clf.fit(train_dataset, labelset)\n",
    "    print(nb_clf.likelihood_0)\n",
    "    testset = []\n",
    "    test1 = setOfWords2Vec(VocabList, ['love', 'my', 'dalmation'])\n",
    "    test2 = setOfWords2Vec(VocabList, ['stupid', 'garbage'])\n",
    "    testset.append(test1)\n",
    "    testset.append(test2)\n",
    "    testset = np.array(testset)\n",
    "    result = nb_clf.predict(testset)\n",
    "    print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 2, 1, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.randint(1, 3, 10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 5, 7, 8], dtype=int64),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(a==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "b = list().append([1, 2, 3])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(list([1, 2, 3]))\n",
    "b = np.array(([2, 3, 4]))\n",
    "\n",
    "a = a.reshape(1, -1)\n",
    "b = b.reshape(1, -1)\n",
    "np.concatenate((np.array(a), np.array(b)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cpu]",
   "language": "python",
   "name": "conda-env-pytorch_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
