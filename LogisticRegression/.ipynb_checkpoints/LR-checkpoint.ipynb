{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "0.6274165202108963\n"
     ]
    }
   ],
   "source": [
    "# -*- coding=utf-8 -*-\n",
    "# @Time :2021/7/18 9:00\n",
    "# @Author :Lu runyu\n",
    "# @File : LR.ipynb\n",
    "# @Software : Jupyter Notebook\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# 防止溢出\n",
    "# 防止数值溢出可以在指数段减去max(x)，这样数值关系不会发生变化。\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    填补此处\n",
    "    \"\"\"\n",
    "\n",
    "    return np.exp(x) / (1 + np.exp(x))\n",
    "\n",
    "\n",
    "# Sigmoid=np.vectorize(sigmoid)\n",
    "\n",
    "\n",
    "class LogisticRegression(object):\n",
    "\n",
    "    def __init__(self, penalty='l2', tol=0.0001, C=1.0, bias=True, max_iter=100,learning_rate=0.0001):\n",
    "        '''\n",
    "\n",
    "        :param penalty: 'l1' or 'l2' 默认：’l2‘ 选择正则化方式\n",
    "        :param tol: min_error 默认：1e-4 迭代停止的最小的误差\n",
    "        :param C: 默认：1.0 惩罚系数\n",
    "        :param bias: 默认：True 是否需要偏差 b\n",
    "        :param max_iter: 默认：1000 最大迭代次数\n",
    "        :param learning_rate 默认：0.01 学习率\n",
    "        '''\n",
    "        self.penalty = penalty\n",
    "        self.tol = tol\n",
    "        self.C = C\n",
    "        self.bais = bias\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate=learning_rate\n",
    "        # 待训练的参数\n",
    "        self.theta=None\n",
    "        self.W = None\n",
    "        self.dW = None\n",
    "        \n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        '''\n",
    "\n",
    "        :param x_train: 训练数据集\n",
    "        :param y_train: 训练标签集 对应数据集的标签 简单应当是二分类的 0，1\n",
    "        :return: this module\n",
    "        '''\n",
    "        assert len(x_train)==len(y_train),'数据集和标签集数量不一致'\n",
    "        assert len(label_set:=np.unique(y_train))==2,'标签集不是二分类的'\n",
    "    \n",
    "        \n",
    "#         x_train, y_train = self.fit_transform(x_train, y_train)\n",
    "        self.W = np.random.randint(-5, 5, x_train.shape[1])\n",
    "        print(self.W.shape)\n",
    "        cnt = 0\n",
    "        while cnt < self.max_iter:\n",
    "            cnt += 1\n",
    "            self.dW = self.gradient_function(x_train, y_train)\n",
    "            self.step(x_train, y_train)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def fit_transform(self,x_train,y_train):\n",
    "        '''\n",
    "\n",
    "                :param x_train: 训练数据集\n",
    "                :param y_train: 训练标签集 对应数据集的标签 简单应当是二分类的 0，1\n",
    "                :return: this module\n",
    "        '''\n",
    "         \n",
    "        \"\"\"\n",
    "        将矩阵归一化、标准化？\n",
    "        \"\"\"\n",
    "        x_train_max = np.max(x_train, axis=0)\n",
    "        x_train = x_train / x_train_max\n",
    "        \n",
    "        self.fit(x_train, y_train)\n",
    "        \n",
    "\n",
    "        \n",
    "    # 预测函数\n",
    "    def predict(self,x_test):\n",
    "        '''\n",
    "\n",
    "        :param x_test: 测试集\n",
    "        :return: y_predict 预测标签\n",
    "        '''\n",
    "        y1 = np.dot(x_test, self.W)\n",
    "        z = sigmoid(y1)\n",
    "        return np.array([0 if z[i] > 0.5 else 1 for i in range(len(z))])\n",
    "        \n",
    "        \n",
    "        \n",
    "    # 打分函数\n",
    "    def score(self,x_test,y_test):\n",
    "        '''\n",
    "\n",
    "        :param x_test: 测试集\n",
    "        :param y_test: 测试标签\n",
    "        :return: 正确率\n",
    "        '''\n",
    "        \n",
    "        diff = x_test - y_test\n",
    "        return diff.tolist().count(0) / len(diff)\n",
    "        pass\n",
    "    # 损失函数\n",
    "    def cost_function(self,x,y,batch_size):\n",
    "        \"\"\"\n",
    "        填补此处\n",
    "        \"\"\"\n",
    "#         print(x.shape, self.W.shape)\n",
    "        y1 = np.dot(x, self.W)\n",
    "        z = sigmoid(y1)\n",
    "        LW = 0 - sum([np.log(z[i])  if y[i] == 1 else np.log(1 - z[i]) for i in range(len(y))])  / len(z)\n",
    "        return z\n",
    "        \n",
    "    # 系数更新函数\n",
    "    def step(self,x,y):\n",
    "        \"\"\"\n",
    "        填补此处\n",
    "        \"\"\"\n",
    "#         print(self.W.shape, self.dW.shape)\n",
    "        self.W = self.W - self.learning_rate * self.dW\n",
    "        \n",
    "        \n",
    "    # 梯度计算函数\n",
    "    def gradient_function(self,data,label):\n",
    "        '''\n",
    "\n",
    "        :param data: 训练数据\n",
    "        :param label: 训练标签\n",
    "        :return:\n",
    "        '''\n",
    "        return np.sum(np.array([i * item for i, item in zip((label - self.cost_function(data, label, data.shape[0])), data)]), axis=0) / data.shape[0]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = np.loadtxt(r'breast_cancer.csv', dtype=np.float64, delimiter=',')\n",
    "    x_train = data[:, :-1]\n",
    "    y_train = data[:, -1]\n",
    "    LR=LogisticRegression(penalty='l1')\n",
    "    LR.fit_transform(x_train=x_train.copy(),y_train=y_train.copy())\n",
    "    print(LR.score(LR.predict(x_train), y_train))\n",
    "#     print(LR.cost_function(x_train, y_train, x_train.shape[0]))\n",
    "    # from sklearn.linear_model import LogisticRegression\n",
    "    # LR2 = LogisticRegression(penalty='l2',C=0.5,solver='liblinear')\n",
    "    # LR2.fit(x_train, y_train)\n",
    "    # print(LR2.score(x_train,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activa(x):\n",
    "    print(np.max(x))\n",
    "    x = x - np.max(x)\n",
    "    return np.exp(x) / (1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [3, 4, 5000000]])\n",
    "activa(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_tile_dispatcher() missing 1 required positional argument: 'reps'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c5e80bbba7b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtile\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: _tile_dispatcher() missing 1 required positional argument: 'reps'"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "np.tile(a, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9560632688927944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR2 = LogisticRegression(penalty='l2',C=0.5,solver='liblinear')\n",
    "LR2.fit(x_train, y_train)\n",
    "print(LR2.score(x_train,y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cpu]",
   "language": "python",
   "name": "conda-env-pytorch_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
